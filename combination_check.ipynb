{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#captioning files\n",
    "for _ in [\"raw\", \"line\"]:\n",
    "    img_folder = f\"/home/paneah/lora_training_guide/dataset/juntae/juntae_{_}\"\n",
    "    command = f\"python3 finetune/make_captions.py --batch_size=1 --num_beams=1 --top_p=0.9 --max_length=75 --min_length=5 --beam_search --caption_extension=.txt \\\n",
    "                            {img_folder} --caption_weights=https://storage.googleapis.com/sfr-vision-language-research/BLIP/models/model_large_caption.pth\"\n",
    "    os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#preparing data folder for training \n",
    "repeat = 5\n",
    "\n",
    "for _ in [\"raw\", \"line\"]:\n",
    "    original_folder = f\"/home/paneah/lora_training_guide/dataset/juntae/juntae_{_}/*\"\n",
    "    os.system(f\"mkdir -p /home/paneah/lora_training_guide/dataset/tmp/images/{repeat}_juntae\")\n",
    "    tmp_folder = f\"/home/paneah/lora_training_guide/dataset/tmp/images/{repeat}_juntae\"\n",
    "    os.system(f\"cp -R {original_folder} {tmp_folder}\")\n",
    "train_dir = f\"/home/paneah/lora_training_guide/dataset/tmp/images\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/paneah/lora_training_guide/result/juntae_5_0.0001_2023-12-22_15:17:45 \n",
      " /home/paneah/stable-diffusion-webui/models/Stable-diffusion/animefull.ckpt /home/paneah/lora_training_guide/dataset/tmp/images\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "2023-12-22 15:17:51.889097: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 15:17:51.889184: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 15:17:51.889219: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 15:17:51.896532: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 15:17:51.924724: E tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:9342] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-12-22 15:17:51.924794: E tensorflow/compiler/xla/stream_executor/cuda/cuda_fft.cc:609] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-12-22 15:17:51.924834: E tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:1518] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-12-22 15:17:51.931506: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-22 15:17:52.995455: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-12-22 15:17:52.999630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c104cuda9SetDeviceEi'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n",
      "usage: train_network.py [-h] [--v2] [--v_parameterization]\n",
      "                        [--pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH]\n",
      "                        [--tokenizer_cache_dir TOKENIZER_CACHE_DIR]\n",
      "                        [--train_data_dir TRAIN_DATA_DIR] [--shuffle_caption]\n",
      "                        [--caption_extension CAPTION_EXTENSION]\n",
      "                        [--caption_extention CAPTION_EXTENTION]\n",
      "                        [--keep_tokens KEEP_TOKENS]\n",
      "                        [--caption_prefix CAPTION_PREFIX]\n",
      "                        [--caption_suffix CAPTION_SUFFIX] [--color_aug]\n",
      "                        [--flip_aug]\n",
      "                        [--face_crop_aug_range FACE_CROP_AUG_RANGE]\n",
      "                        [--random_crop] [--debug_dataset]\n",
      "                        [--resolution RESOLUTION] [--cache_latents]\n",
      "                        [--vae_batch_size VAE_BATCH_SIZE]\n",
      "                        [--cache_latents_to_disk] [--enable_bucket]\n",
      "                        [--min_bucket_reso MIN_BUCKET_RESO]\n",
      "                        [--max_bucket_reso MAX_BUCKET_RESO]\n",
      "                        [--bucket_reso_steps BUCKET_RESO_STEPS]\n",
      "                        [--bucket_no_upscale]\n",
      "                        [--token_warmup_min TOKEN_WARMUP_MIN]\n",
      "                        [--token_warmup_step TOKEN_WARMUP_STEP]\n",
      "                        [--dataset_class DATASET_CLASS] [--mask_dir MASK_DIR]\n",
      "                        [--shift_images_dir SHIFT_IMAGES_DIR]\n",
      "                        [--caption_dropout_rate CAPTION_DROPOUT_RATE]\n",
      "                        [--caption_dropout_every_n_epochs CAPTION_DROPOUT_EVERY_N_EPOCHS]\n",
      "                        [--caption_tag_dropout_rate CAPTION_TAG_DROPOUT_RATE]\n",
      "                        [--reg_data_dir REG_DATA_DIR] [--in_json IN_JSON]\n",
      "                        [--dataset_repeats DATASET_REPEATS]\n",
      "                        [--output_dir OUTPUT_DIR] [--output_name OUTPUT_NAME]\n",
      "                        [--huggingface_repo_id HUGGINGFACE_REPO_ID]\n",
      "                        [--huggingface_repo_type HUGGINGFACE_REPO_TYPE]\n",
      "                        [--huggingface_path_in_repo HUGGINGFACE_PATH_IN_REPO]\n",
      "                        [--huggingface_token HUGGINGFACE_TOKEN]\n",
      "                        [--huggingface_repo_visibility HUGGINGFACE_REPO_VISIBILITY]\n",
      "                        [--save_state_to_huggingface]\n",
      "                        [--resume_from_huggingface] [--async_upload]\n",
      "                        [--save_precision {None,float,fp16,bf16}]\n",
      "                        [--save_every_n_epochs SAVE_EVERY_N_EPOCHS]\n",
      "                        [--save_every_n_steps SAVE_EVERY_N_STEPS]\n",
      "                        [--save_n_epoch_ratio SAVE_N_EPOCH_RATIO]\n",
      "                        [--save_last_n_epochs SAVE_LAST_N_EPOCHS]\n",
      "                        [--save_last_n_epochs_state SAVE_LAST_N_EPOCHS_STATE]\n",
      "                        [--save_last_n_steps SAVE_LAST_N_STEPS]\n",
      "                        [--save_last_n_steps_state SAVE_LAST_N_STEPS_STATE]\n",
      "                        [--save_state] [--resume RESUME]\n",
      "                        [--enable_hypertile ENABLE_HYPERTILE]\n",
      "                        [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                        [--max_token_length {None,150,225}] [--mem_eff_attn]\n",
      "                        [--xformers] [--sdpa] [--vae VAE]\n",
      "                        [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                        [--max_train_epochs MAX_TRAIN_EPOCHS]\n",
      "                        [--max_data_loader_n_workers MAX_DATA_LOADER_N_WORKERS]\n",
      "                        [--persistent_data_loader_workers] [--seed SEED]\n",
      "                        [--gradient_checkpointing]\n",
      "                        [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                        [--mixed_precision {no,fp16,bf16}] [--full_fp16]\n",
      "                        [--full_bf16] [--ddp_timeout DDP_TIMEOUT]\n",
      "                        [--clip_skip CLIP_SKIP] [--logging_dir LOGGING_DIR]\n",
      "                        [--log_with {tensorboard,wandb,all}]\n",
      "                        [--log_prefix LOG_PREFIX]\n",
      "                        [--log_tracker_name LOG_TRACKER_NAME]\n",
      "                        [--log_tracker_config LOG_TRACKER_CONFIG]\n",
      "                        [--wandb_api_key WANDB_API_KEY]\n",
      "                        [--noise_offset NOISE_OFFSET]\n",
      "                        [--multires_noise_iterations MULTIRES_NOISE_ITERATIONS]\n",
      "                        [--ip_noise_gamma IP_NOISE_GAMMA]\n",
      "                        [--multires_noise_discount MULTIRES_NOISE_DISCOUNT]\n",
      "                        [--adaptive_noise_scale ADAPTIVE_NOISE_SCALE]\n",
      "                        [--zero_terminal_snr] [--min_timestep MIN_TIMESTEP]\n",
      "                        [--max_timestep MAX_TIMESTEP] [--lowram]\n",
      "                        [--sample_every_n_steps SAMPLE_EVERY_N_STEPS]\n",
      "                        [--sample_every_n_epochs SAMPLE_EVERY_N_EPOCHS]\n",
      "                        [--sample_prompts SAMPLE_PROMPTS]\n",
      "                        [--sample_sampler {ddim,pndm,lms,euler,euler_a,heun,dpm_2,dpm_2_a,dpmsolver,dpmsolver++,dpmsingle,k_lms,k_euler,k_euler_a,k_dpm_2,k_dpm_2_a}]\n",
      "                        [--config_file CONFIG_FILE] [--output_config]\n",
      "                        [--metadata_title METADATA_TITLE]\n",
      "                        [--metadata_author METADATA_AUTHOR]\n",
      "                        [--metadata_description METADATA_DESCRIPTION]\n",
      "                        [--metadata_license METADATA_LICENSE]\n",
      "                        [--metadata_tags METADATA_TAGS]\n",
      "                        [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
      "                        [--optimizer_type OPTIMIZER_TYPE] [--use_8bit_adam]\n",
      "                        [--use_lion_optimizer] [--learning_rate LEARNING_RATE]\n",
      "                        [--max_grad_norm MAX_GRAD_NORM]\n",
      "                        [--optimizer_args [OPTIMIZER_ARGS ...]]\n",
      "                        [--lr_scheduler_type LR_SCHEDULER_TYPE]\n",
      "                        [--lr_scheduler_args [LR_SCHEDULER_ARGS ...]]\n",
      "                        [--lr_scheduler LR_SCHEDULER]\n",
      "                        [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                        [--lr_scheduler_num_cycles LR_SCHEDULER_NUM_CYCLES]\n",
      "                        [--lr_scheduler_power LR_SCHEDULER_POWER]\n",
      "                        [--use_external_webui USE_EXTERNAL_WEBUI]\n",
      "                        [--webui_url WEBUI_URL] [--webui_auth WEBUI_AUTH]\n",
      "                        [--should_wait_webui_process SHOULD_WAIT_WEBUI_PROCESS]\n",
      "                        [--dataset_config DATASET_CONFIG]\n",
      "                        [--min_snr_gamma MIN_SNR_GAMMA]\n",
      "                        [--scale_v_pred_loss_like_noise_pred]\n",
      "                        [--v_pred_like_loss V_PRED_LIKE_LOSS]\n",
      "                        [--debiased_estimation_loss] [--weighted_captions]\n",
      "                        [--no_metadata]\n",
      "                        [--save_model_as {None,ckpt,pt,safetensors}]\n",
      "                        [--unet_lr UNET_LR]\n",
      "                        [--text_encoder_lr TEXT_ENCODER_LR]\n",
      "                        [--network_weights NETWORK_WEIGHTS]\n",
      "                        [--network_module NETWORK_MODULE]\n",
      "                        [--network_dim NETWORK_DIM]\n",
      "                        [--network_alpha NETWORK_ALPHA]\n",
      "                        [--network_dropout NETWORK_DROPOUT]\n",
      "                        [--network_args [NETWORK_ARGS ...]]\n",
      "                        [--network_train_unet_only]\n",
      "                        [--network_train_text_encoder_only]\n",
      "                        [--training_comment TRAINING_COMMENT]\n",
      "                        [--dim_from_weights]\n",
      "                        [--scale_weight_norms SCALE_WEIGHT_NORMS]\n",
      "                        [--base_weights [BASE_WEIGHTS ...]]\n",
      "                        [--base_weights_multiplier [BASE_WEIGHTS_MULTIPLIER ...]]\n",
      "                        [--no_half_vae] [--process_title PROCESS_TITLE]\n",
      "                        [--gor_num_groups GOR_NUM_GROUPS]\n",
      "                        [--gor_regularization_type GOR_REGULARIZATION_TYPE]\n",
      "                        [--gor_name_to_regularize GOR_NAME_TO_REGULARIZE]\n",
      "                        [--gor_regularize_fc_layers GOR_REGULARIZE_FC_LAYERS]\n",
      "                        [--gor_ortho_decay GOR_ORTHO_DECAY]\n",
      "                        [--gor_regularization GOR_REGULARIZATION]\n",
      "                        [--mask_loss MASK_LOSS]\n",
      "                        [--mask_loss_weight MASK_LOSS_WEIGHT]\n",
      "                        [--mask_threshold MASK_THRESHOLD]\n",
      "                        [--mask_path MASK_PATH]\n",
      "train_network.py: error: unrecognized arguments: 1231231\n",
      "usage: train_network.py [-h] [--v2] [--v_parameterization]\n",
      "                        [--pretrained_model_name_or_path PRETRAINED_MODEL_NAME_OR_PATH]\n",
      "                        [--tokenizer_cache_dir TOKENIZER_CACHE_DIR]\n",
      "                        [--train_data_dir TRAIN_DATA_DIR] [--shuffle_caption]\n",
      "                        [--caption_extension CAPTION_EXTENSION]\n",
      "                        [--caption_extention CAPTION_EXTENTION]\n",
      "                        [--keep_tokens KEEP_TOKENS]\n",
      "                        [--caption_prefix CAPTION_PREFIX]\n",
      "                        [--caption_suffix CAPTION_SUFFIX] [--color_aug]\n",
      "                        [--flip_aug]\n",
      "                        [--face_crop_aug_range FACE_CROP_AUG_RANGE]\n",
      "                        [--random_crop] [--debug_dataset]\n",
      "                        [--resolution RESOLUTION] [--cache_latents]\n",
      "                        [--vae_batch_size VAE_BATCH_SIZE]\n",
      "                        [--cache_latents_to_disk] [--enable_bucket]\n",
      "                        [--min_bucket_reso MIN_BUCKET_RESO]\n",
      "                        [--max_bucket_reso MAX_BUCKET_RESO]\n",
      "                        [--bucket_reso_steps BUCKET_RESO_STEPS]\n",
      "                        [--bucket_no_upscale]\n",
      "                        [--token_warmup_min TOKEN_WARMUP_MIN]\n",
      "                        [--token_warmup_step TOKEN_WARMUP_STEP]\n",
      "                        [--dataset_class DATASET_CLASS] [--mask_dir MASK_DIR]\n",
      "                        [--shift_images_dir SHIFT_IMAGES_DIR]\n",
      "                        [--caption_dropout_rate CAPTION_DROPOUT_RATE]\n",
      "                        [--caption_dropout_every_n_epochs CAPTION_DROPOUT_EVERY_N_EPOCHS]\n",
      "                        [--caption_tag_dropout_rate CAPTION_TAG_DROPOUT_RATE]\n",
      "                        [--reg_data_dir REG_DATA_DIR] [--in_json IN_JSON]\n",
      "                        [--dataset_repeats DATASET_REPEATS]\n",
      "                        [--output_dir OUTPUT_DIR] [--output_name OUTPUT_NAME]\n",
      "                        [--huggingface_repo_id HUGGINGFACE_REPO_ID]\n",
      "                        [--huggingface_repo_type HUGGINGFACE_REPO_TYPE]\n",
      "                        [--huggingface_path_in_repo HUGGINGFACE_PATH_IN_REPO]\n",
      "                        [--huggingface_token HUGGINGFACE_TOKEN]\n",
      "                        [--huggingface_repo_visibility HUGGINGFACE_REPO_VISIBILITY]\n",
      "                        [--save_state_to_huggingface]\n",
      "                        [--resume_from_huggingface] [--async_upload]\n",
      "                        [--save_precision {None,float,fp16,bf16}]\n",
      "                        [--save_every_n_epochs SAVE_EVERY_N_EPOCHS]\n",
      "                        [--save_every_n_steps SAVE_EVERY_N_STEPS]\n",
      "                        [--save_n_epoch_ratio SAVE_N_EPOCH_RATIO]\n",
      "                        [--save_last_n_epochs SAVE_LAST_N_EPOCHS]\n",
      "                        [--save_last_n_epochs_state SAVE_LAST_N_EPOCHS_STATE]\n",
      "                        [--save_last_n_steps SAVE_LAST_N_STEPS]\n",
      "                        [--save_last_n_steps_state SAVE_LAST_N_STEPS_STATE]\n",
      "                        [--save_state] [--resume RESUME]\n",
      "                        [--enable_hypertile ENABLE_HYPERTILE]\n",
      "                        [--train_batch_size TRAIN_BATCH_SIZE]\n",
      "                        [--max_token_length {None,150,225}] [--mem_eff_attn]\n",
      "                        [--xformers] [--sdpa] [--vae VAE]\n",
      "                        [--max_train_steps MAX_TRAIN_STEPS]\n",
      "                        [--max_train_epochs MAX_TRAIN_EPOCHS]\n",
      "                        [--max_data_loader_n_workers MAX_DATA_LOADER_N_WORKERS]\n",
      "                        [--persistent_data_loader_workers] [--seed SEED]\n",
      "                        [--gradient_checkpointing]\n",
      "                        [--gradient_accumulation_steps GRADIENT_ACCUMULATION_STEPS]\n",
      "                        [--mixed_precision {no,fp16,bf16}] [--full_fp16]\n",
      "                        [--full_bf16] [--ddp_timeout DDP_TIMEOUT]\n",
      "                        [--clip_skip CLIP_SKIP] [--logging_dir LOGGING_DIR]\n",
      "                        [--log_with {tensorboard,wandb,all}]\n",
      "                        [--log_prefix LOG_PREFIX]\n",
      "                        [--log_tracker_name LOG_TRACKER_NAME]\n",
      "                        [--log_tracker_config LOG_TRACKER_CONFIG]\n",
      "                        [--wandb_api_key WANDB_API_KEY]\n",
      "                        [--noise_offset NOISE_OFFSET]\n",
      "                        [--multires_noise_iterations MULTIRES_NOISE_ITERATIONS]\n",
      "                        [--ip_noise_gamma IP_NOISE_GAMMA]\n",
      "                        [--multires_noise_discount MULTIRES_NOISE_DISCOUNT]\n",
      "                        [--adaptive_noise_scale ADAPTIVE_NOISE_SCALE]\n",
      "                        [--zero_terminal_snr] [--min_timestep MIN_TIMESTEP]\n",
      "                        [--max_timestep MAX_TIMESTEP] [--lowram]\n",
      "                        [--sample_every_n_steps SAMPLE_EVERY_N_STEPS]\n",
      "                        [--sample_every_n_epochs SAMPLE_EVERY_N_EPOCHS]\n",
      "                        [--sample_prompts SAMPLE_PROMPTS]\n",
      "                        [--sample_sampler {ddim,pndm,lms,euler,euler_a,heun,dpm_2,dpm_2_a,dpmsolver,dpmsolver++,dpmsingle,k_lms,k_euler,k_euler_a,k_dpm_2,k_dpm_2_a}]\n",
      "                        [--config_file CONFIG_FILE] [--output_config]\n",
      "                        [--metadata_title METADATA_TITLE]\n",
      "                        [--metadata_author METADATA_AUTHOR]\n",
      "                        [--metadata_description METADATA_DESCRIPTION]\n",
      "                        [--metadata_license METADATA_LICENSE]\n",
      "                        [--metadata_tags METADATA_TAGS]\n",
      "                        [--prior_loss_weight PRIOR_LOSS_WEIGHT]\n",
      "                        [--optimizer_type OPTIMIZER_TYPE] [--use_8bit_adam]\n",
      "                        [--use_lion_optimizer] [--learning_rate LEARNING_RATE]\n",
      "                        [--max_grad_norm MAX_GRAD_NORM]\n",
      "                        [--optimizer_args [OPTIMIZER_ARGS ...]]\n",
      "                        [--lr_scheduler_type LR_SCHEDULER_TYPE]\n",
      "                        [--lr_scheduler_args [LR_SCHEDULER_ARGS ...]]\n",
      "                        [--lr_scheduler LR_SCHEDULER]\n",
      "                        [--lr_warmup_steps LR_WARMUP_STEPS]\n",
      "                        [--lr_scheduler_num_cycles LR_SCHEDULER_NUM_CYCLES]\n",
      "                        [--lr_scheduler_power LR_SCHEDULER_POWER]\n",
      "                        [--use_external_webui USE_EXTERNAL_WEBUI]\n",
      "                        [--webui_url WEBUI_URL] [--webui_auth WEBUI_AUTH]\n",
      "                        [--should_wait_webui_process SHOULD_WAIT_WEBUI_PROCESS]\n",
      "                        [--dataset_config DATASET_CONFIG]\n",
      "                        [--min_snr_gamma MIN_SNR_GAMMA]\n",
      "                        [--scale_v_pred_loss_like_noise_pred]\n",
      "                        [--v_pred_like_loss V_PRED_LIKE_LOSS]\n",
      "                        [--debiased_estimation_loss] [--weighted_captions]\n",
      "                        [--no_metadata]\n",
      "                        [--save_model_as {None,ckpt,pt,safetensors}]\n",
      "                        [--unet_lr UNET_LR]\n",
      "                        [--text_encoder_lr TEXT_ENCODER_LR]\n",
      "                        [--network_weights NETWORK_WEIGHTS]\n",
      "                        [--network_module NETWORK_MODULE]\n",
      "                        [--network_dim NETWORK_DIM]\n",
      "                        [--network_alpha NETWORK_ALPHA]\n",
      "                        [--network_dropout NETWORK_DROPOUT]\n",
      "                        [--network_args [NETWORK_ARGS ...]]\n",
      "                        [--network_train_unet_only]\n",
      "                        [--network_train_text_encoder_only]\n",
      "                        [--training_comment TRAINING_COMMENT]\n",
      "                        [--dim_from_weights]\n",
      "                        [--scale_weight_norms SCALE_WEIGHT_NORMS]\n",
      "                        [--base_weights [BASE_WEIGHTS ...]]\n",
      "                        [--base_weights_multiplier [BASE_WEIGHTS_MULTIPLIER ...]]\n",
      "                        [--no_half_vae] [--process_title PROCESS_TITLE]\n",
      "                        [--gor_num_groups GOR_NUM_GROUPS]\n",
      "                        [--gor_regularization_type GOR_REGULARIZATION_TYPE]\n",
      "                        [--gor_name_to_regularize GOR_NAME_TO_REGULARIZE]\n",
      "                        [--gor_regularize_fc_layers GOR_REGULARIZE_FC_LAYERS]\n",
      "                        [--gor_ortho_decay GOR_ORTHO_DECAY]\n",
      "                        [--gor_regularization GOR_REGULARIZATION]\n",
      "                        [--mask_loss MASK_LOSS]\n",
      "                        [--mask_loss_weight MASK_LOSS_WEIGHT]\n",
      "                        [--mask_threshold MASK_THRESHOLD]\n",
      "                        [--mask_path MASK_PATH]\n",
      "train_network.py: error: unrecognized arguments: 1231231\n",
      "ERROR:torch.distributed.elastic.multiprocessing.api:failed (exitcode: 2) local_rank: 0 (pid: 9445) of binary: /home/paneah/lora_training_guide/kohya_ss/venv/bin/python\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/bin/accelerate\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/accelerate/commands/accelerate_cli.py\", line 47, in main\n",
      "    args.func(args)\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 977, in launch_command\n",
      "    multi_gpu_launcher(args)\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/accelerate/commands/launch.py\", line 646, in multi_gpu_launcher\n",
      "    distrib_run.run(args)\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torch/distributed/run.py\", line 785, in run\n",
      "    elastic_launch(\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 134, in __call__\n",
      "    return launch_agent(self._config, self._entrypoint, list(args))\n",
      "  File \"/home/paneah/lora_training_guide/kohya_ss/venv/lib/python3.10/site-packages/torch/distributed/launcher/api.py\", line 250, in launch_agent\n",
      "    raise ChildFailedError(\n",
      "torch.distributed.elastic.multiprocessing.errors.ChildFailedError: \n",
      "============================================================\n",
      "train_network.py FAILED\n",
      "------------------------------------------------------------\n",
      "Failures:\n",
      "[1]:\n",
      "  time      : 2023-12-22_15:17:59\n",
      "  host      : DESKTOP-JV09R37.localdomain\n",
      "  rank      : 1 (local_rank: 1)\n",
      "  exitcode  : 2 (pid: 9446)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "------------------------------------------------------------\n",
      "Root Cause (first observed failure):\n",
      "[0]:\n",
      "  time      : 2023-12-22_15:17:59\n",
      "  host      : DESKTOP-JV09R37.localdomain\n",
      "  rank      : 0 (local_rank: 0)\n",
      "  exitcode  : 2 (pid: 9445)\n",
      "  error_file: <N/A>\n",
      "  traceback : To enable traceback see: https://pytorch.org/docs/stable/elastic/errors.html\n",
      "============================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#training LoRA \n",
    "from datetime import datetime\n",
    "\n",
    "now = datetime.now()\n",
    "\n",
    "epoch = 1\n",
    "learning_rate = 1e-4\n",
    "batch = 2\n",
    "\n",
    "output_dir = f\"/home/paneah/lora_training_guide/result/juntae_{repeat}_{learning_rate}_{now.strftime('%Y-%m-%d_%H:%M:%S')}\"\n",
    "model_name = \"animefull.ckpt\"\n",
    "base_model = f\"/home/paneah/stable-diffusion-webui/models/Stable-diffusion/{model_name}\"\n",
    "\n",
    "print(output_dir, \"\\n\", base_model, train_dir)\n",
    "\n",
    "command = f\"accelerate launch train_network.py --enable_bucket --train_batch_size={batch} --caption_extension=.txt --max_train_epochs={epoch} --resolution=512,512 --pretrained_model_name_or_path={base_model} --train_data_dir={train_dir} --output_dir={output_dir} --prior_loss_weight=1.0 --train_batch_size=1 --learning_rate={learning_rate} --use_8bit_adam --xformers --mixed_precision=fp16 --save_every_n_epochs=1 --save_model_as=safetensors --clip_skip=2 --seed=42 --color_aug --network_module=networks.lora\"\n",
    "\n",
    "os.system(command)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "paneah     158    92  0 Dec21 pts/0    00:02:24 /home/paneah/.vscode-server/bin/0ee08df0cf4527e40edc9aa28f4b5bd38bbff2b2/node /home/paneah/.vscode-server/extensions/ms-python.vscode-pylance-2023.12.1/dist/server.bundle.js --cancellationReceive=file:fbdddf9e552207f9915c86a380a014ada5a6e3438d --node-ipc --clientProcessId=92\n",
      "paneah     476   458 39 Dec21 pts/4    10:00:16 python3 -u launch.py\n",
      "paneah    4873 26758  0 14:51 ?        00:00:02 /home/paneah/lora_training_guide/kohya_ss/venv/bin/python -m ipykernel_launcher -f /home/paneah/.local/share/jupyter/runtime/kernel-c347ca92-b479-44cc-bba2-ac6a42984f6c.json\n",
      "paneah   11531  4873  0 15:25 pts/9    00:00:00 /bin/bash -c ps -ef | grep python\n",
      "paneah   11533 11531  0 15:25 pts/9    00:00:00 grep python\n",
      "paneah   26124 26071  0 Dec21 pts/6    00:02:15 python /home/paneah/lora_training_guide/kohya_ss/kohya_gui.py\n",
      "paneah   26758 26341  0 Dec21 pts/8    00:00:40 /home/paneah/lora_training_guide/kohya_ss/venv/bin/python /home/paneah/lora_training_guide/kohya_ss/venv/bin/jupyter-server --port 7682\n"
     ]
    }
   ],
   "source": [
    "#inference\n",
    "webui_path = \"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
